# -*- coding: utf-8 -*-
"""GAN_scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p_hNeo7WmwRmL8nc6IqEF53BV1uc-p2P
"""

import pickle
import socket
import torch
import torchvision

import numpy as np

import matplotlib.pyplot as plt

from tqdm import tqdm

from models import Generator, Discriminator, weights_init
from constants import *

if socket.gethostname() == "mba2020.local":
    DATA_ROOT = "/Users/yuto/ML_data/"
elif socket.gethostname() == "lxkura":
    DATA_ROOT = "/home/hamada/ML/data/celeba/"
else:
    DATA_ROOT = "/content/drive/MyDrive/celeba/data/"
print(f"DATA_ROOT: {DATA_ROOT}")

# prepare data
dataset = torchvision.datasets.ImageFolder(
    root=DATA_ROOT,
    transform=torchvision.transforms.Compose([
        torchvision.transforms.Resize(IMAGE_SIZE),
        torchvision.transforms.CenterCrop(IMAGE_SIZE),
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]),
)
dataloader = torch.utils.data.DataLoader(
    dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=N_WORKERS,
    drop_last=True
)
real_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(DEVICE)[:64], normalize=True).cpu(), (1, 2, 0)))


# create instances
gen_model = Generator(ngpu=1).to(DEVICE)
discri_model = Discriminator(ngpu=1).to(DEVICE)
gen_model.apply(weights_init)
discri_model.apply(weights_init)
# check
z_tmp = torch.randn(64, 100, 1, 1, device=DEVICE)
plt.figure(figsize=(8, 8))
plt.imshow(np.transpose(torchvision.utils.make_grid(gen_model(z_tmp), normalize=True).cpu(), (1, 2, 0)))
print(discri_model(gen_model(z_tmp)).squeeze())

# init loss function and optimzer
criterion = torch.nn.BCELoss()
optimizer_gen = torch.optim.Adam(gen_model.parameters(), lr=OPTIM_LR, betas=(BETA1, 0.999))
optimizer_discri = torch.optim.Adam(discri_model.parameters(), lr=OPTIM_LR, betas=(BETA1, 0.999))

# for visualization of training progress
fixed_noise = torch.randn(64, N_Z, 1, 1, device=DEVICE)

img_list = []
losses_gen = []
losses_discri = []
iters = 0

for epoch in tqdm(range(N_EPOCHS), desc='epoch'):
    for i, (real_img, _) in enumerate(tqdm(dataloader, desc='batch')):
        # D real train
        # init
        discri_model.zero_grad()
        # to device
        real_img = real_img.to(DEVICE)
        # make label (all label is REAL_LABEL)
        label = torch.full((BATCH_SIZE,), REAL_LABEL, dtype=torch.float, device=DEVICE)
        # forward propagation
        output = discri_model(real_img).view(-1)
        # calc loss
        loss_discri_real = criterion(output, label)
        # back propagation
        loss_discri_real.backward()

        # D fake train
        noise = torch.randn(BATCH_SIZE, N_Z, 1, 1, device=DEVICE)
        # make fake image
        fake_image = gen_model(noise)
        label.fill_(FAKE_LABEL)
        # forward propagation
        output = discri_model(fake_image.detach()).view(-1)
        # calc loss
        loss_discri_fake = criterion(output, label)
        # back propagation
        loss_discri_fake.backward()
        optimizer_discri.step()
        # prepare
        loss_discri = loss_discri_real + loss_discri_fake

        # G train
        gen_model.zero_grad()
        # make label
        label.fill_(REAL_LABEL)
        # forward propagation
        output = discri_model(fake_image).view(-1)
        # calc loss
        loss_gen = criterion(output, label)
        # back propagation
        loss_gen.backward()
        optimizer_gen.step()

        # save progress
        losses_discri.append(loss_discri.item())
        losses_gen.append(loss_gen.item())
        if (iters % 500 == 0) or ((epoch == N_EPOCHS-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake_image = gen_model(fixed_noise).detach().cpu()
            img_list.append(torchvision.utils.make_grid(fake_image, padding=2, normalize=True))

        iters += 1

# save
model_path = "gan_scrath_{}.pth"
torch.save(gen_model.state_dict(), model_path.format("gen"))
torch.save(discri_model.state_dict(), model_path.format("discri"))

# pickle
pickle_filename = "pickles/{}.pickle"
with open(pickle_filename.format("losses_gen"), 'wb') as f:
    pickle.dump(losses_gen, f)
with open(pickle_filename.format("losses_discri"), 'wb') as f:
    pickle.dump(losses_discri, f)
with open(pickle_filename.format("img_list"), 'wb') as f:
    pickle.dump(img_list, f)
